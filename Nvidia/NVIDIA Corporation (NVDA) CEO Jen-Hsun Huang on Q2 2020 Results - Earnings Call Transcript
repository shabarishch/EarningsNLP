{"data": {"id": "4286222", "type": "fullArticle", "attributes": {"publishOn": "2019-08-16T08:42:06-04:00", "isLockedPro": false, "commentCount": 7, "gettyImageUrl": null, "videoPreviewUrl": null, "themes": {"sa-transcripts": {"id": 96991, "slug": "sa-transcripts", "kind": "common", "non_theme": true}, "nvda": {"id": 1150, "slug": "nvda", "kind": "common", "non_theme": true}, "technology": {"id": 17994, "slug": "technology", "kind": "common", "path": "/stock-ideas/technology", "title": "Tech\u00a0", "non_theme": true}, "transcripts": {"id": 49, "slug": "transcripts", "kind": "general", "path": "/earnings/earnings-call-transcripts", "title": "Transcripts"}, "has-audio": {"id": 586376, "slug": "has-audio", "kind": "general"}, "us": {"id": 326, "slug": "us", "kind": "common", "non_theme": true}, "semiconductor-specialized": {"id": 18020, "slug": "semiconductor-specialized", "kind": "common", "non_theme": true}, "information-technology": {"id": 45, "slug": "information-technology", "kind": "sector", "path": "/stock-ideas/technology", "title": "Tech\u00a0", "sasource": "theme_breadcrumb"}}, "title": "NVIDIA Corporation (NVDA) CEO Jen-Hsun Huang on Q2 2020 Results - Earnings Call Transcript", "summary": [], "isPaywalled": false, "lastModified": "2020-05-28T04:34:50-04:00", "isModerated": false, "closestTradingDate": "2019-08-16", "beforeOpeningHours": true, "proPublishOn": "2019-08-16T08:42:06-04:00", "isEarningsSlides": false, "isExclusive": false, "isTranscript": true, "excludedByTag": false, "transcriptPath": "https://static.seekingalpha.com/cdn/s3/transcripts_audio/4286222.mp3", "likesCount": 6, "disabledStatus": "allowed", "disabledMessage": null, "status": "published", "disclosure": "", "articleActionableItem": null, "inEmbargo": false, "isNoindex": false, "isNoarchive": true, "content": "<p>NVIDIA Corporation (<span class=\"ticker-hover-wrapper\">NASDAQ:<a href=\"https://seekingalpha.com/symbol/NVDA\" title=\"NVIDIA Corporation\">NVDA</a></span>) Q2 2020 Earnings Conference Call August 15, 2019 5:30 PM ET</p> <p><strong>Company Participants</strong></p> <p>Simona Jankowski - Investor Relations<br> Jen-Hsun Huang - President and Chief Executive Officer<br> Colette Kress - Executive Vice President and Chief Financial Officer</p> <p><strong>Conference Call Participants</strong></p> <p>C.J. Muse - Evercore<br> Vivek Arya - Bank of America Merrill Lynch<br> Toshiya Hari - Goldman Sachs<br> Harlan Sur - JPMorgan<br> Timothy Arcuri - UBS<br> Matt Ramsay - Cowen<br> Joe Moore - Morgan Stanley<br> Aaron Rakers - Wells Fargo<br> Stacy Rasgon - Bernstein Research</p> <p><strong>Operator</strong></p> <p>Good afternoon. My name is Christina, and I will be your conference operator today. Welcome to NVIDIA\u2019s financial results conference call. [Operator Instructions] I will now turn the call over to Simona Jankowski from Investor Relations to begin your conference.</p> <p><strong>Simona Jankowski</strong></p> <p>Thank you. Good afternoon, everyone and welcome to NVIDIA\u2019s conference call for the second quarter of fiscal 2020. With me on the call today from NVIDIA are Jen-Hsun Huang, President and Chief Executive Officer and Colette Kress, Executive Vice President and Chief Financial Officer.</p> <p>I would like to remind you that our call is being webcast live on NVIDIA\u2019s Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the third quarter of fiscal 2020. The content of today\u2019s call is NVIDIA\u2019s property. It can\u2019t be reproduced or transcribed without our prior written consent.</p> <p>During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today\u2019s earnings release, our most recent Form 10-K and 10-Q and the reports that we may file on Form 8-K with the Securities<span class=\"paywall-full-content invisible\"> and Exchange Commission. All our statements are made as of today, August 15, 2019, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial<span class=\"paywall-full-content no-summary-bullets invisible\"> measures to GAAP financial measures in our CFO commentary, which is posted on our website.</span></span></p> <p class=\"paywall-full-content invisible no-summary-bullets\">With that, let me turn the call over to Colette.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Colette Kress</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Thanks, Simona. Q2 revenue was $2.58 billion, in line with our outlook, down 17% year-on-year and up 16% sequentially. Starting with our gaming business, revenue of $1.31 billion was down 27% year-on-year and up 24% sequentially. We are pleased with the strong sequential growth in the quarter when we launched our RTX SUPER lineup for desktop gamers, wrapped up our greatest ever number of gaming laptops and launched our new RTX studio laptops for creators.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">In July, we unveiled 3 GeForce RTX SUPER GPUs, delivering the best-in-class gaming performance and power efficiency and real-time ray tracing for both current and next-generation games. These GPUs delivered a performance boost of up to 24% from our initial Turing GPUs launched a year earlier. The SUPER lineup strengthens our leadership in the high end of the market and the response has been great. We look forward to delighting gamers with the best performance in ray tracing as we get into the back to school and holiday shopping seasons. Ray tracing is taking the gaming industry by storm and have quickly come to define the modern era of computer graphics. A growing number of blockbuster AAA titles have announced support for NVIDIA RTX ray tracing, including Call of Duty: Modern Warfare, Cyberpunk 2077, Watch Dogs: Legion and Wolfenstein: Youngblood.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">Excitement around these titles is tremendous. GameSpot called Cyberpunk one of the most anticipated games of the decade. NVIDIA GeForce RTX are the only graphic cards in the market with hardware support for ray tracing. They deliver a 2 to 3x performance speed up over GPUs without a dedicated ray tracing core. The laptop business continues to be a standout growth driver as OEMs are ramping a record 100-plus gaming laptop models ahead of the back to school and holiday season. The combination of our energy-efficient Turing architecture and Max-Q technology enables beautifully crafted thin and light form factors that can deliver the performance of high-end gaming desktop or our next-generation console.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">At Computex in May, we unveiled NVIDIA RTX Studio laptops, a new design artist platform that extends our reach to the large, underserved market of creators. In the age of YouTube, creators and freelancers are rapidly growing population, but they have traditionally not had access to professional-grade workstations through online and retail channels. RTX Studio laptops are designed to meet their increasing complex workflows such as photorealistic ray tracing, AI image enhancement and ultra high-resolution video. Powered by our RTX GPUs and optimized software, RTX Studio laptops deliver performance that\u2019s up to 7x faster than that of the MacBook Pro. A total of 27 RTX Studio models have been announced by major OEMs. Sequential growth also benefited from the production ramp of the two new models of Nintendo Switch gaming console. We are expecting our console business to remain strong in Q3 before the seasonal production slowdown in Q4 when console-related revenue is expected to be fairly minimal, similar to last year.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">Moving to data center, revenue was $655 million, down 14% year-on-year and up 3% sequentially. In the vertical industries portion of the business, expanding AI workload drove sequential and year-over-year growth. In hyperscale portion, we continue to be impacted by relatively weak overall spending at a handful of CSPs. Sales of NVIDIA GPUs for use in the cloud were solid. While sales of internal hyperscale use were muted, the engineering focus on AI is growing.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">Let me give some color on each of these areas. We are building a broad base of customers across multiple industries as they adopt NVIDIA\u2019s platforms to harness the power of AI. Public sectors, higher education and financial services were among the key verticals driving growth this quarter. In addition, we won Lighthouse account deals in important industries that are on the cusp of being transformed by AI. For example, in retail, Wal-Mart is using NVIDIA GPUs to run some of its product demand forecasting models, slashing the time to do so in just 4 hours from several weeks on CPUs. By accelerating its data science workflow, Wal-Mart can improve its algorithms, reduce development cycles and test new features.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">Earlier this week, we announced breakthroughs for the fastest training and inference of the state-of-the-art model for natural language process understanding called BERT, or Bidirectional Encoder Representations from Transformers, a breakthrough AI language model that achieves a deeper sense of language, context and meaning. This can enable mere human comprehension in real-time by chat box, intelligent personal assistants and search engines. We are working with Microsoft as an early adopter of these advances. AI computing leadership is a high priority for NVIDIA. Last month, we set records for training deep learning neural network models on the latest MLPerf benchmarks, particularly in the most demanding areas. In just 7 months, we have achieved up to 80% speed-ups enabled by new algorithms and software optimizations across the full stack while using the same hardware. This is a direct result of the productive programming environment and flexibility of CUDA.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">Delivering AI at scale isn\u2019t just about silicon. It\u2019s about optimizing across the entire high-performance computing system. In fact, the NVIDIA AI platform is getting progressively faster. Every month, we publish new optimization and performance improvements to CUDA-X AI libraries, supporting every AI framework and development environment. All in, our ecosystem of developers is now 1.4 million strong. In setting these MLPerf records, we leveraged our new DGX SuperPOD AI supercomputer, demonstrating that leadership in AI research demands leadership in computing infrastructure. This system debuted in June at #22 on the TOP500 list of the world\u2019s fastest supercomputers at the annual International Supercomputing Conference. Used to meet the massive demand for autonomous vehicle development program, it is powered by more than 1,500 NVIDIA V100 Tensor Core GPUs linked with Mellanox interconnects. We have made DGX SuperPOD available commercially to customers, essentially providing them with the turnkey supercomputer that they can assemble in weeks rather than months. It is roughly 400x smaller in size than other similarly performing TOP500 systems, which are built from thousands of servers. Also at the conference, we announced that by next year\u2019s end, we will make available to the ARM ecosystem NVIDIA\u2019s full stack of AI and HPC software, which accelerates more than 600 HPC applications and all AI frameworks. With this announcement, NVIDIA will accelerate all major CPU architectures, including x86, POWER and ARM. Lastly, regarding our pending acquisition of Mellanox, we have received regulatory approval in the U.S. and are engaged with regulators in Europe and China. The approval process is progressing as expected, and we continue to work toward closing the deal by the end of this calendar year.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">Moving to pro visualization, revenue reached $291 million, up 4% from our prior year and up 9% sequentially. Year-on-year and sequential growth was led by record revenue for mobile workstations with strong demand for new thin and light form factors. We had a great showing at SIGGRAPH, the computer graphics industry\u2019s biggest annual conference held in Los Angeles. Our researchers won several Best in Show awards. In just a year since the launch of RTX ray tracing, over 40 design and creative applications with RTX technology had been announced by leading software vendors, including Adobe, Autodesk and Dassault systems and many others. NVIDIA RTX technology has reinvigorated the computer graphics industry by enabling researchers and developers to take a leap in photorealistic rendering, augmented reality and virtual reality.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">Finally, turning to automotive, Q2 revenue was $209 million, up 30% from a year ago and up 26% sequentially. This reflects growing adoption of next-generation AI cockpit solutions and autonomous vehicle development projects, including one particularly sizable development services transaction that was recognized in the quarter. In addition, in June, we announced a new partnership with the Volvo Group to develop AI and autonomous trucks utilizing NVIDIA\u2019s end-to-end AI platform for training, simulation and in-vehicle computing. The strategic partnership will enable Volvo Group to develop a wide range of autonomous driving solutions for freight transport, recycling collection, public transport, construction, mining, forestry and more. This collaboration is a great validation of our long-held position that every vehicle, not just cars but also trucks, shuttles, business, taxis and many others, will have autonomous capability 1 day. Autonomous features can bring enormous value to the trucking industry, in particular as the demand of online shopping put ever greater stress on the world\u2019s transport systems. Expectations for overnight or same-day deliveries create challenges that can only be met by autonomous trucks, which can operate 24 hours a day. To help address these needs, NVIDIA has created an end-to-end platform for autonomous vehicles from AI computing infrastructure to large-scale simulation to in-car computing. Multiple customers from OEMs like Mercedes-Benz, Toyota and Volvo to Tier 1s like Bosch, Continental and ZF are already onboard. We see this as a $30 billion addressable market by 2025.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">Moving to the rest of the P&amp;L, Q2 GAAP gross margins was 59.8% and non-GAAP was 60.1%, up sequentially, reflecting higher automotive development services, a favorable mix in gaming and lower component cost. GAAP operating expenses were $970 million, and non-GAAP operating expenses were $749 million, up 19% and 8% year-on-year, respectively. We remain on track for high single-digit OpEx growth in fiscal 2020 while continuing to invest in the key platforms driving our long-term growth, namely graphics, AI and self-driving cars. GAAP EPS was $0.90, down 49% from a year earlier. Non-GAAP EPS was $1.24, down 36% from a year ago.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">With that, let me turn to the outlook for the third quarter of fiscal 2020. We expect revenue to be $2.9 billion, plus or minus 2%. GAAP and non-GAAP gross margins are expected to be 62% and 62.5%, respectively, plus or minus 50 basis points. GAAP and non-GAAP operating expenses are expected to be approximately $980 million and $765 million, respectively. GAAP and non-GAAP OI&amp;E are both expected to be income of approximately $25 million. GAAP and non-GAAP tax rates are both expected to be 10%, plus or minus 1%, excluding discrete items. Capital expenditures are expected to be approximately $100 million to $120 million. Further financial details are included in the CFO commentary and other information available on our IR website.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">In closing, let me highlight upcoming events for the financial community. We will be at the Jefferies conference, hardware and communications infrastructure summit, on August 27 and at the Citi Global Technology Conference on September 25. With that, we will now open the call for questions. Operator, would you please poll for the questions?</p> <p id=\"question-answer-session\" class=\"paywall-full-content invisible no-summary-bullets\"><strong>Question-and-Answer Session</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Operator</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">[Operator Instructions] And your first question comes from the line of C.J. Muse with Evercore.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"question\">C.J. Muse</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Good afternoon. Thank you for taking the questions. I guess first question on gaming, how should we think about your outlook into the October quarter vis-\u00e0-vis kind of normal seasonality? How are you thinking about Switch within that? And considering now that you have full Turing lineup as well as content truly coming to the forefront here, how do you think about trends beyond the October quarter? Thank you.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Jen-Hsun Huang</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Sure. Colette, why don\u2019t you take the Switch question? And then I will take the rest of the RTX questions.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Colette Kress</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Sure. From a gaming perspective, the overall Switch or the overall console business definitely is a seasonal business. We usually expect to see production ramping in Q2 and in Q3, with it coming down likely in Q4. So you should see Switch to be a portion definitely of our gaming business in Q3.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Jen-Hsun Huang</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Yes. C.J., thanks for your question. RTX as you know is \u2013 first of all, RTX is doing great. I think we have put all the pieces in place to bring ray tracing into the future of games. The number of games, the blockbuster games that adopted RTX is really snowballing. We announced several 6 games in the last couple of months. There is going to be some exciting announcements next week at gamescom. It\u2019s pretty clear now the future of gaming will include ray tracing. The number of software developers that create \u2013 with creative tools that adopted RTX is really quite spectacular. We now have 40 \u2013 over 40 ISV tools that was announced at SIGGRAPH that have accelerated ray tracing and video editing. And some of the applications\u2019 amazing AI capabilities for image optimization enhancement support RTX.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">And so looking forward, this is what I expect. I expect that ray tracing is going to drive a reinvigoration of gaming graphics. I expect that the over 100 laptops that we have RTX designed \u2013 RTX GPUs designed into is going to contribute our growth. Notebook gaming is one of the fastest-growing segments of the gaming platform world. The number of notebooks that are able to game is only a few percent, so it\u2019s extremely underexposed. And yet, we know that gamers are \u2013 like the rest of us, they like thin and light notebooks, but they like it to be able to run powerful games. And so this is an area that has grown significantly for us year-over-year, and we\u2019re expecting it to grow through the end of the \u2013 through the second half and through next year. And one of the things that\u2019s really exciting is our RTX Studio line that we introduced recently. We observed, and through our discussions with the PC industry, that the creatives are really underexposed and underserved by the latest technologies. And they want notebooks and they want PCs that have powerful graphics. They use it for 3D content creation and high-definition video editing and image optimization and things like that. And we introduced a brand-new line of computers that we call RTX Studio. Now the OEMs were so excited about it. And at SIGGRAPH, we now have 27 different laptops shipping and more coming. And so I think RTX is really geared for growth. We have great games coming. We got the SUPER line of GPUs. We have all of our notebooks that were designed into that we are ramping and of course, the new RTX Studio line. And so I expect this to be a growth market for us.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"question\">Christopher James</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Very helpful. If I could follow-up on the data center side, perhaps you can speak directly just to the hyperscale side, both internal and cloud, and whether you\u2019re seeing any green shoots, any signs of life there and how you are thinking about what that rate of recovery could look like over time?</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Jen-Hsun Huang</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">With the exception of a couple of hyperscalers, C.J., I would \u2013 we\u2019re seeing broad-based growth in data centers. In the area of training, the thing that\u2019s really exciting everybody, and everybody is racing towards, is training these large gigantic natural language understanding models, language models. The transformer model that was introduced by Google, called BERT, has since been enhanced into XLned and RoBERTa and, gosh, so many different, GP2, and Microsoft\u2019s MASS. And there are so many different versions of these language models. And in the AI, NLU, natural language understanding, is one of the most important areas that everybody\u2019s racing to go to. And so, these models are really, really large. It\u2019s over 1,000x larger than image models that we\u2019re training just a few years ago, and they\u2019re just gigantic models. It\u2019s one of the reasons why we built the DGX SuperPOD so that we could train these gigantic models in a reasonable amount of time. The second area \u2013 so that\u2019s training in the hyperscalers. The second area where we are seeing enormous amounts of activity has to do with trying to put these conversational AI models into services so that they could be interactive and in real time. Whereas photo tagging and photo enhancement is something that you could put off-line and you could do that while you have excess capacity when it\u2019s off of the most busy time of the day. You can\u2019t do that with language and conversational AI. You better to respond to the person in real time. And so the performance that\u2019s required is significant. But more importantly, the number of models necessary for conversational AI from speech recognition to language understanding to recommendation systems to text-to-speech to wave synthesis these 5, 6, 7 models have to be processed in real time \u2013 in series and in real time so that you can have a reasonable conversation with the AI agent. And so these type of activities is really driving interest and activity at all of the hyperscalers. My expectation is that this is going to continue to be a big growth opportunity for us. But more importantly, in addition to that, we\u2019re seeing that AI is \u2013 the wave of AI is going from the cloud to the enterprise to the edge and all the way out to the autonomous systems. The place where we\u2019re seeing a lot of excitement, and we talked about that in the past and we\u2019re seeing growth there, has to do with the vertical industry enterprises that are starting to adopt AI to create new products, whether it\u2019s a delivery robot or some kind of a Chat Bot or the ability to detect fraud in financial services, these applications in vertical industries are really spreading all over the place. There\u2019s some over 4,000 AI start-ups around the world. And the way that we engage them is they use our platform to start developing AI in the cloud. And as you know, we\u2019re the only AI platform that\u2019s available on-prem and in every single cloud. And so they can use our AI platforms for \u2013 in all the clouds, which is driving our cloud computing, external cloud computing growth. And then they can also use it on-prem if their usage really grows significantly. And that\u2019s one of the reasons why our Tesla for OEMs and DGX is growing. And so we\u2019re seeing broad-based excitement around AI as they use it for their products and new services. And these 4,000, 4,500 start-ups around the world is really driving consumption of that.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Operator</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">And your next question comes from the line of Vivek Arya with Bank of America Merrill Lynch.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"question\">Vivek Arya</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Alright thanks for taking my questions. I actually had 2 as well, one quick one for Colette and one for Jensen. Colette, good to see the gross margin recovery getting into October is this 62% to 63% range a more sustainable level and perhaps a level you could grow off of as sales get more normalized levels? And then a bigger question is for Jensen. Again, on the data center side, Jensen, when I look back between \u2013 2015 to 2018, your data center business essentially grew 10x. And then the last year has been a tough one with the slowdown in cloud CapEx and so forth. When do you think your data center starts to grow back on a year-to-year \u2013 on a year-on-year basis? Can that happen sometime \u2013 later this year? And then just longer term, what is the right way to think about this business? Does it go back to prior levels? Does it go at a different phase? This is the one part of the business that I think is toughest for us to model, so any color would be very helpful.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Colette Kress</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Great, so let me start first with your question, Vivek, regarding gross margins. Yes, thanks for recognizing that we are moving towards our expectations that, over time, we\u2019ll continue to see our overall volumes improve. Essentially, our business is normalized. We\u2019ve reached normalized levels through the last couple of quarters. And this quarter, just very similar to what we will see going forward, is mix is the largest driver, what drives our overall gross margins and our gross margin improvements.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Jen-Hsun Huang</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Yes, Vivek, if you look at the last several years, there\u2019s no question our data center business has grown a lot. And my expectation is that it\u2019s going to grow a lot more, and let me explain to you why. Aside from a couple \u2013 a few of uncontrollable circumstances and the exception of a couple of large customers, the overall trend, the broad-based trend, of our data center business is upward, to the right. And it is growing very nicely. There\u2019s a couple of different dynamics that\u2019s causing that on first principles to grow. And of course, one of them is as AI is well known now to require accelerated computing, our computing architecture is really ideal for it. AI is not just one network. It\u2019s thousands of different types of networks, and these networks are getting more and more complex over time, the amount of data you have to process is enormous. And so like all software programs, you cannot predict exactly how the software is going to get programmed. And having a programmable architecture like CUDA and yet optimized for AI like Tensor Cores that we\u2019ve created is really the ideal architecture.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">We know also that AI is the most powerful technology force of our time. The ability for machines to learn and write software by itself and write software that no humans can write is pretty extraordinary. And the applications of AI, as you guys are watching yourself, are just spreading in every single industry. And so the way we think about AI is in waves, if you will. The first wave of AI is developing the computer architecture, and that was the first part where \u2013 that\u2019s when a lot of people discovered who we are, and we emerged into the world of high-performance computing in AI. The second wave is applying the AI for cloud service providers or hyperscalers. They have a large amount of data. They have a lot of consumer applications. Many of them are not life-critical and so, therefore, the application of an early technology \u2013 early-adoption technology was really viable. And so you saw hyperscalers adopt AI. And the thing that\u2019s really exciting for us is beyond recommendations, beyond image enhancement, the area where we believe the most important application for AI is likely conversational AI. Most people talking and asking questions and talking to their mobile devices and looking for something or asking for directions instead of having a page of \u2013 a list of options, it responds with an answer that is very likely a good one. The next phase of AI is what we call vertical industry enterprise AI. And this is where companies are using it not just to accelerate the business process internally, but they\u2019re using AI to create new products and services. They could be new medical instruments to IoT-based medical instruments to monitor your health. It could be something related to an application that \u2013 used for financial services for forecasting or for fraud detection. It could be some kind of device that delivers pizza to you, delivery bots. And the combination of IoT and artificial intelligence, for the very first time, you actually have the software capabilities to make use of all of these sensors that you\u2019re putting all over the world. And that\u2019s the next phase of growth. And it affects companies from large industrials, transportation companies, retailers, you name it. Health care companies, you name it. And so that phase of growth of AI is the phase that we\u2019re about to enter into.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">And then the longer term is an industry that we all know to be extremely large, but it takes time because it\u2019s life-critical, and it has to do with transportation. It\u2019s a $100 trillion industry. We know it\u2019s going to be automated. We know that everything that moves in the future will be autonomous or have autonomous capabilities. And that\u2019s just a matter of time before we realize its full potential. And so the net of it all is that I believe that AI is the single most powerful technology force of our time, and that\u2019s why we\u2019re all in on it. And we know that acceleration and accelerated computing is the perfect model for that. And it started in the cloud, but it\u2019s going to keep moving out into the edge and through data centers and enterprises and hopefully \u2013 well, eventually, all the way out into autonomous devices and machines in the real world. And so this is a big market, and I\u2019m super enthusiastic about it.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Operator</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">And your next question comes from the line of Toshiya Hari with Goldman Sachs.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"question\">Toshiya Hari</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Hi guys. Thanks very much for taking the questions. I had two as well, one for Jensen and the other for Colette. Jensen, you guys called out inference as a significant contributor to growth in data center last quarter. I think you guys talked about it being a double-digit percentage contributor, curious what you saw from inference in the quarter. And more importantly, if you can talk about the outlook, both near term and long term, as it relates to inference, that\u2019ll be helpful. And then secondly, for Colette, just want to double click on the gross margin question. The sequential improvement that you\u2019re guiding to is a pretty significant number. So I was just hoping if you can kind of break it down for us in terms of overall volume growth mix dynamics, both between segments and within segments and also to the extent DRAM pricing is impacting that, any color on that will be helpful as well. Thank you.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Jen-Hsun Huang</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Yes, Toshiya, I got to tell you, I\u2019m less good at normal pre \u2013 near-term productions than I am good at thinking about long-term dynamics. But let me talk to you about inference. Our inference business is \u2013 remains robust. It\u2019s double digits. It\u2019s a large part of our business. And \u2013 but more importantly, the two dynamics that I think are near term and that\u2019s going to drive growth, number one is interactive conversational AI, interactive conversational AI inference. If you simply ask a chat bot a simple question, where is the closest pizza and you would \u2013 pizza shop, and you would like to have a conversation with this bot, it would have to do speech recognition, it has to understand what it is that you asked about, it has to look it up in a recommender based on the locations you\u2019re at, maybe your preferences of styles of pizza and the price ranges that you\u2019re interested and how far you\u2019re willing to go, to go get it. It has to recommend a pizza shop for you to go to. It has to then translate that from text-to-speech and then into human \u2013 a human understand a voice. And those models have to happen in just a few \u2013 ideally, a few hundred milliseconds. Currently, it\u2019s not that. And it makes it really hard for these services to be deployed quite broadly and used for all kinds of different applications. And so that\u2019s the near-term opportunity, it\u2019s interactive conversational AI inference. And you could just imagine every single hyperscaler racing to go make this possible because recently, we had some important breakthroughs in machine learning language models. The BERT model that I mentioned earlier is really, really an important development, and it\u2019s caused a large number of derivatives that has improved upon it and so near-term conversational AI inference. But, we are also seeing near term the inference at the edge. There are many types of applications where because of the laws of physics reasons, the speed of light reasons or the economics reasons or data sovereignty reasons, it\u2019s not possible to stream the data to the cloud and have the inference done at the cloud. You have to do that at the edge. You need the latency to be low, the amount of data that you\u2019re streaming is continuous. And so you don\u2019t want to be paying for that line rate the whole time, and maybe the data is of great confidentiality or privacy. And so we\u2019re seeing a lot of excitement and a lot of development for edge AI. Smart retail, smart warehouses, smart factories, smart cities, smart airports, you just make a list of those kind of things, basically locations where there is a lot of activity, where safety or cost or large amount of materials is passing through, you could just imagine the applications. All of those really want to be edge computing systems and edge inference systems. And so those are near term \u2013 two near-term drivers, and I think it\u2019s fair to say that both of them are quite large opportunities.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Colette Kress</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">So to answer your question regarding gross margin in a little bit more detail, probably our largest area that we expect improvement in terms of our mix is our mix return regarding our overall gaming business. We expect to have a full quarter of our SUPER lineup within the next quarter including our RTX as well as our notebook becoming a bigger mix as well as it grows. These drivers are one of the largest reasons why we see that growth in our gross margin. We always think about our component cost, our overall cost of manufacturing, so this is always baked in over time, but we\u2019ll continue to see improvements on that as well.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Operator</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">And your next question comes from the line of Harlan Sur with JPMorgan.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"question\">Harlan Sur</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Good afternoon. Thanks for taking my question. Again on your data center business, many of your peers on the compute and storage side are seeing spending recovery by cloud and hyperscalers in the second half of this year after a similar weak first half of the year. You guys saw some growth in Q2 driven primarily by enterprise. It seems like you had some broadening out of the customer spending this quarter. Inferencing continues to see strong momentum. Would you guys expect that this translates into a double-digit percentage sequential growth in data center in Q3 off of the low base in Q2?</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Jen-Hsun Huang</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Our hyperscale data center with a few customers don\u2019t give us very much \u2013 we don\u2019t get very much visibility from a handful of customers in hyperscale. However, we\u2019re seeing broad-based growth and excitement in data centers. And the way to think about data center, our data center business consists of hyperscale training, internal training, hyperscale inference, cloud computing \u2013 and that\u2019s hyperscale, and that cloud is a public cloud. And then we have vertical industry enterprise, what sometimes we call enterprise, vertical industry enterprise, it could be transportation companies, retailers, telcos, vertical industry adoption of AI either to accelerate their business or to develop new products and services. And then the \u2013 so when you look at our data center from that perspective and these pieces, although we don\u2019t see as much \u2013 we don\u2019t get as much visibility as we like in a couple of the large customers, the rest of the hyperscalers, we\u2019re seeing broad-based growth. And so we\u2019re experiencing the enthusiasm and the energy that maybe the others are and so we will keep updating you guys as we go. We will see how it goes.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Operator</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">And your next question comes from the line of Timothy Arcuri with UBS.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"question\">Timothy Arcuri</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Thanks a lot. I had two. I guess first for Jensen, Volta\u2019s been around now for about 2 years. Do you see signs of demand maybe building up ahead of the new set of nanometer products, whenever that comes out? I guess I\u2019m just wondering whether there\u2019s some element of this is more around product cadence that gets resolved as you do roll out the product. That\u2019s the first question. And then I guess, the second question, Colette, is of the $300 million growth into October, it sounds like Switch is pretty flat, but I\u2019m wondering if you can give us maybe some qualitative sense of where the growth is coming from, is it maybe like two-third gaming and one-third data centers, something like that? Thanks.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Jen-Hsun Huang</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Well, Volta data center products can churn that fast. We gamers could churn products quickly because they\u2019re bought and sold one at a time. But data centers data center infrastructure really has to be planned properly, and the build-out takes time. And we expect Volta to be successful all the way through next year. And software still continues to be improved on it. We\u2019re still improving systems on it. And in fact, just 1 year in just 1 year, we improved our AI performance on Volta by almost 2x, 80%. And so, you could just imagine the amount of software that\u2019s built on top of Volta and all the Tensor Cores and all the GPUs connected with NVLink and the large number of nodes that are connected to build supercomputers. The software of building these systems, large-scale systems, is really, really hard. And that\u2019s one of the reasons why you hear people talk about chips, but they never show up because building the software is just an enormous undertaking. The number of software engineers we have in the company is in the thousands, and we have the benefit of having built on top of this architecture for over 1.5 decades. And so, when we\u2019re able to deploy into data centers as quickly as we do, I think we kind of lose sight of how hard it is to do that in the first place. The last time a new processor entered into a data center was an x86 Xeon, and you just don\u2019t bring processors in the data centers that frequently or that easily. And so, I think the way to think about Volta is that it\u2019s surely in its prime, and it\u2019s going to keep continue to do well all the way through next year.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Colette Kress</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">In regard to our guidance on revenue, and we do guide in terms of the total. You have seen, in this last quarter, we executed a sequential increase really focusing on moving to a normalization of our gaming business. And we\u2019re now approaching the second half of the year getting ready for the back to school and the holidays. So, you should expect also our gaming business to continue to grow to reach that full normalization by the end of Q3. We do expect the rest of our platforms to likely also grow. We have a couple different models on how that will come out. But yes, we do expect our data center business to grow, and then we\u2019ll see on the rest of our businesses as well.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Operator</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Your next question comes from the line of Matt Ramsay with Cowen.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"question\">Matt Ramsay</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Thank you very much. Good afternoon. A couple of questions. I guess the first one is Jensen, if you have any, I guess, high-level qualitative commentary on how the new SUPER upgrades of your Turing platform have been received in the market and how you might think about them progressing through the year. And then, I guess, the second question is a bigger one. Intel\u2019s talked quite openly about One API. The software stack at Xilinx is progressing with Versal ACAP. I mean you guys get a lot of credit for the decade of work that you\u2019ve done on CUDA. But I wonder if you might comment on if you\u2019ve seen any movement in the competitive landscape on the software side for the data center space. Thank you.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Jen-Hsun Huang</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">SUPER is off to a great start. Goodness, SUPER is off to a super start. And if you look at if you do channel checks all over, even though we\u2019ve got a lot of products in the channel and we last quarter was a transitional quarter for us actually. And we didn\u2019t we shipped SUPER later in the quarter. But because the entire ecosystem and all of our execution engines are so primed, we were able to ship a fair number through the channel. And so, and yet, if you do spot checks all around the world, they\u2019re sold out almost everywhere. And the pricing in the spot market is drifting higher than MSRP. That just tells you something about demand. And so that\u2019s really exciting. SUPER is off to a super start for and at this point, it\u2019s a foregone conclusion that we\u2019re going to buy a new graphics card, and it\u2019s going to the last 2, 3, 4 years to not have ray tracing is just crazy. Ray tracing content just keeps coming out. And between the performance of SUPER and the fact that it has ray tracing hardware, it\u2019s going to be super well positioned for throughout all of next year.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">Your question about APIs and software programmability, APIs is just one of the issues. The large issue about processors is how do you program it. The reason why x86s and CPUs are so popular is because they solve the great challenge of software developers: how to program a computer and how to program a computer and how to compile for that computer is a paramount concern to computer science, and it\u2019s an area of tremendous research. Going from single CPU to multi-core CPUs was a great challenge. Going from multi-core CPUs to multi-node multi-core CPUs is an enormous challenge. And yet, when we created CUDA in our GPUs, we went from 1 CPU core or one processor core to a few to now, in the case of large-scale systems, millions of processor cores. And how do you program such a computer across multi-GPU, multi-node? It\u2019s a concept that\u2019s not easy to grasp. And so, I don\u2019t really know how one programming approach or a simple API is going to make 7 different type of weird things work together. And I can\u2019t make it fit in my head. But programming isn\u2019t as simple as a PowerPoint slide, I guess. And I think it\u2019s just time will tell whether one programming approach could fit 7 different types of processors when no time in history has it ever happened.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Operator</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Your next question comes from the line of Joe Moore with Morgan Stanley.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"question\">Joe Moore</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Great. thank you. I wonder if you could talk about the strength in the automotive business. Looks like the services piece of that is getting to be bigger, what\u2019s the outlook for that part of the business? And can you give us a sense of the mix between services and components at this point?</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Jen-Hsun Huang</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Sure. Thanks, Joe. Our approach to autonomous vehicles comes in basically 2 parts. The first part is a full stack, which is building the architected processor, the system, the system software and all of the driving applications on top, including the deep neural nets. The second part of it, we call that a full stack self-driving car computer. The second part of DRIVE includes an end-to-end AV development system. For those who would like to use our processors, use our system software but create their own applications, we created a system that allows basically shares with them our computing infrastructure that we built for ourselves that allows them to do end-to-end development from deep learning development to the application of AV to simulating that application to doing regression testing of that application before they deploy it into a car. And the two systems that we use there is called DGX for training and Constellation for simulation and what is called Replay. And then the third part of our business model is development agreements, otherwise known as NRE. These 3 elements, full stack computer, end-to-end development flow and NRE project development product development consists of the overall DRIVE business. And so, although the cars will take several years to go into production, we\u2019re seeing a lot of interest in working with us to develop self-driving cars using our development systems and entering into development projects. And so, we\u2019re the number of autonomous vehicle projects is quite large around the world as you can imagine. And so, my sense is that we\u2019re going to continue to do well here. The additional part of autonomous vehicles and where the capability has been derived and is going to seal up more near-term opportunities has to do with things like delivery shuttles, self-driving shuttles and maybe cargo movers inside walled warehouses. Those kinds of autonomous machines require basically the same technology, but it\u2019s sooner and easier to deploy. And so, we are seeing a lot of excitement around that area.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Operator</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Your next question comes from the line of Aaron Rakers with Wells Fargo.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"question\">Aaron Rakers</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Yes, thanks for taking the questions and congratulations on the improved performance. At your Analyst Day back a couple of months ago, you had highlighted the installed base opportunity for RTX. And I think at that point in time, you talked about 50% being Pascal base, 48% being pre-Pascal. You also alluded to the fact that you were seeing a positive mix shift higher in terms of the price points of this RTX cycle. So, I\u2019m curious, where do we stand on the current product cycle? And what are you seeing currently as we go through this product cycle on the Turing platforms?</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Jen-Hsun Huang</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">We launched well, first of all, the answer is that RTX adoption is faster than Pascal\u2019s adoption if you normalize to time 0 of launch. The reason for that is Pascal launched top to bottom on the same day. And as you guys know, we weren\u2019t able to do that for Turing. But if we did that for Turing, the adoption rate is actually faster. And to me, it\u2019s a rather sensible. And the reason for that is because Pascal was basically DX12. And Maxwell was DX12. And Turing is the world\u2019s first DXR, the first ray tracing GPU, brand-new functionality, brand-new API and a lot more performance. And so, I think it\u2019s sensible that Turing\u2019s adoption is going to be rapid. The second element of Turing is something that we\u2019ve never talked about before. We\u2019re mentioning it more and more because it\u2019s such an exciting book market for us is notebooks. The install base of Pascal has a very, very little notebook in it. And the reason for that is because, in the past, we were never able to put a high-performance gaming GPU into a thin and light notebook until we invented Max-Q. And in combination with our energy efficiency, we were able to we\u2019re now able to put a 2080 into a laptop, and it\u2019s still beautiful. And so, this is effectively a brand-new growth market for us. And with so few people and so few gamers in the world that are able to game on a laptop, I think this is going to be a nice growth market for us.</p> <p class=\"paywall-full-content invisible no-summary-bullets\">And then the new market that we introduced and launched this last quarter is called RTX Studio. And this is an underserved segment of the market where consumers, enthusiasts, they could be artists that are working on small firms, they need powerful computers to do their work. They need powerful computers to do rendering and high-definition video editing. And yet it\u2019s underserved by workstations because workstations are really sold on a B2B basis into large enterprises. And so, we aligned all of the OEMs and created a whole new line of notebooks called RTX Studio. And the enthusiasm has been great. We\u2019ve launched 27 different laptops, and I\u2019m looking forward to seeing the results of that. This is tens of millions of people who are creators. Some of them professionals, some of them hobbyists. And they use Adobe suites, they use Autodesk in their suites and some of them use SolidWorks and some of them use all kinds of renders, like blender. And these are 3D artists and video artists, and this digital content creation is the modern way of creativity. And so, this is an underserved market that we\u2019re excited to go serve with RTX Studio.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Operator</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">And your last question comes from the line of Stacy Rasgon with Bernstein Research.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"question\">Stacy Rasgon</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Hi guys. Thanks for taking my questions. I have two for Colette. My first question is on data center. So, I know you say that you have a broad-based growth except for a few hyperscalers. But you only grew at 3% sequentially, about $20 million. That doesn\u2019t sound like broad-based growth to me unless like did the hyperscalers get worse or are they just still so much bigger than like the rest of it? I guess, what\u2019s going on in data center? How do I wrap my head around like broad-based growth with relatively minimal growth observed?</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong><span class=\"answer\">Colette Kress</span></strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">So, to answer your question here, Stacy, on what we refer to when we\u2019re discussing the broad-based growth is the substantial expansion that we have on the types of customers and the industries that we are now approaching. As you know, even a year ago, we had a very, very small base in terms of industry-based hyper excuse me, industry-based AI workloads that they were using. Over this last quarter, we\u2019re continuing to see strong growth as we roll out all different types of AI solutions, both across the U.S. and worldwide, to these overall customers. Our hyperscalers, again, a couple of them, not necessarily growing, some of them are flat and some of them are growing depending on whether or not that\u2019s for cloud instances or whether or not they\u2019re using it for internal use. So, we believe that our continued growth with the industries is important for us for the long term to expand the use of AI and we are just really pleased with what we are seeing in that growth this quarter.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Operator</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">I\u2019ll now turn the call back over to Jensen for any closing remarks.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Jen-Hsun Huang</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">Thanks, everyone. We are happy with our results this quarter and our return to growth across our platforms. Gaming is doing great. It\u2019s great to see NVIDIA RTX reinvigorating the industry. GeForce has several growth drivers. Ray traced games continue to gain momentum. A large number of gaming laptops are rolling out, and our new Studio platform is reaching the large underserved community of creators. Outside a few hyperscalers, we\u2019re seeing broad-based growth in data centers. AI is the most powerful technology force of our time and a once-in-a-lifetime opportunity. More and more enterprises are using AI to create new products and services while leveraging AI to drive ultra efficiency and speed in their business. And with hyperscalers racing to harness recent breakthroughs in conversational AI, we see growing engagements in training as well as interactive conversational inference. RTX, CUDA accelerated computing, AI, autonomous vehicles, the work we\u2019re doing is important, impactful and incredibly fun. We\u2019re just grateful there is so much of it. We look forward to updating you on our progress next quarter.</p> <p class=\"paywall-full-content invisible no-summary-bullets\"><strong>Operator</strong></p> <p class=\"paywall-full-content invisible no-summary-bullets\">This concludes today\u2019s conference call. You may now disconnect.</p>", "twitContent": "$NVDA - NVIDIA Corporation (NVDA) CEO Jen-Hsun Huang on Q2 2020 Results - Earnings Call Transcript. https://seekingalpha.com/article/4286222-nvidia-corporation-nvda-ceo-jen-hsun-huang-on-q2-2020-results-earnings-call-transcript?source=tweet ", "innerMarketing": null, "marketingBullet": "", "isReit": false, "videoData": null, "marketingBulletVariant": null, "marketingBio": null}, "relationships": {"author": {"data": {"id": "44211", "type": "author"}}, "sentiments": {"data": []}, "primaryTickers": {"data": [{"id": "1150", "type": "tag"}]}, "secondaryTickers": {"data": []}, "otherTags": {"data": [{"id": "96991", "type": "tag"}, {"id": "17994", "type": "tag"}, {"id": "49", "type": "tag"}, {"id": "586376", "type": "tag"}, {"id": "326", "type": "tag"}, {"id": "18020", "type": "tag"}]}, "coAuthors": {"data": []}, "presentations": {"data": []}, "updates": {"data": []}, "corrections": {"data": []}}, "links": {"self": "/article/4286222-nvidia-corporation-nvda-ceo-jen-hsun-huang-on-q2-2020-results-earnings-call-transcript", "canonical": "https://seekingalpha.com/article/4286222-nvidia-corporation-nvda-ceo-jen-hsun-huang-on-q2-2020-results-earnings-call-transcript", "uriImage": "https://static.seekingalpha.com/assets/og_image_1200-29b2bfe1a595477db6826bd2126c63ac2091efb7ec76347a8e7f81ba17e3de6c.png", "schemaImage": null}}, "included": [{"id": "44211", "type": "author", "attributes": {"company": null, "slug": "sa-transcripts", "userId": 101639, "tagId": 96991, "image": {"small": "https://static3.seekingalpha.com/images/users_profile/000/101/639/small_pic.png", "medium": "https://static3.seekingalpha.com/images/users_profile/000/101/639/medium_pic.png", "big": "https://static3.seekingalpha.com/images/users_profile/000/101/639/big_pic.png", "extra_large": "https://static3.seekingalpha.com/images/users_profile/000/101/639/extra_large_pic.png"}, "nick": "SA Transcripts", "bio": "Seeking Alpha's transcripts team is responsible for the development of all of our transcript-related projects. We currently publish thousands of quarterly earnings calls per quarter on our site and are continuing to grow and expand our coverage. The purpose of this profile is to allow us to share with our readers new transcript-related developments. Thanks, SA Transcripts Team", "deactivated": null, "memberSince": 2007, "isRss": false, "contributorSince": 2013, "followersCount": 145436}, "relationships": {"user": {"data": {"id": "101639", "type": "user"}}, "userBioTags": {"data": [{"id": "958652", "type": "userBioTag"}]}, "authorResearch": {"data": null}}, "links": {"self": "/author/sa-transcripts", "profileUrl": "/author/sa-transcripts", "site": null, "linkedinUrl": null, "twitterUrl": null}}, {"id": "1150", "type": "tag", "attributes": {"slug": "nvda", "name": "NVDA", "company": "NVIDIA Corporation", "tagKind": "Tags::Ticker", "equityType": "stocks", "exchange": "NASDAQ", "fundTypeId": 0, "isDefunct": false, "currency": "USD", "isBdc": false, "isReit": false, "isEtf": false}, "relationships": {"sector": {}, "subIndustry": {}}, "links": {"self": "/symbol/NVDA"}}, {"id": "96991", "type": "tag", "attributes": {"slug": "sa-transcripts", "name": "SA Transcripts", "company": null, "tagKind": "Tags::AuthorTag"}, "links": {"self": "/author/sa-transcripts"}}, {"id": "17994", "type": "tag", "attributes": {"slug": "technology", "name": "Technology", "company": null, "tagKind": "Tag"}, "links": {"self": "/tag/technology"}}, {"id": "49", "type": "tag", "attributes": {"slug": "transcripts", "name": "Transcripts", "company": null, "tagKind": "Tag"}, "links": {"self": "/tag/transcripts"}}, {"id": "586376", "type": "tag", "attributes": {"slug": "has-audio", "name": "Has Audio", "company": null, "tagKind": "Tag"}, "links": {"self": "/tag/has-audio"}}, {"id": "326", "type": "tag", "attributes": {"slug": "us", "name": "United States", "company": null, "tagKind": "Tags::Country"}, "links": {"self": "/articles?filters=us"}}, {"id": "18020", "type": "tag", "attributes": {"slug": "semiconductor-specialized", "name": "Semiconductor - Specialized", "company": null, "tagKind": "Tag"}, "links": {"self": "/tag/semiconductor-specialized"}}]}