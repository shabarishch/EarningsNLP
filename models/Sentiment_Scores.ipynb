{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9d60fa-14a5-4b23-9351-1802b9c96b38",
   "metadata": {},
   "source": [
    "# Step 1: Create functions to extract relevant sentences \n",
    "\n",
    "In this section, we define several functions to extract pertinent sentences along with their context. Additionally, we establish various categories to facilitate a thorough analysis of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21df33c9-69fb-4e14-94b2-58510116caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from seaborn import set_style\n",
    "set_style(\"whitegrid\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import spacy\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d04a6ffa-fa68-4649-94f1-6ae5ad883fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the language library\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf6a4ef-d5eb-420d-9551-aa0dfa916ac8",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Helvetica, sans-serif; font-size: 16px; font-weight: bold;\">1a: Named Entity Recognition (NER)</span>\n",
    "\n",
    "In this subsection, we employ Named Entity Recognition (NER) to identify and extract sentences containing entities such as 'MONEY', 'PERCENT', and 'QUANTITY'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61e55a8c-4062-4476-b908-3814b25473d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL        - Numerals that do not fall under another type\n",
      "DATE            - Absolute or relative dates or periods\n",
      "EVENT           - Named hurricanes, battles, wars, sports events, etc.\n",
      "FAC             - Buildings, airports, highways, bridges, etc.\n",
      "GPE             - Countries, cities, states\n",
      "LANGUAGE        - Any named language\n",
      "LAW             - Named documents made into laws.\n",
      "LOC             - Non-GPE locations, mountain ranges, bodies of water\n",
      "MONEY           - Monetary values, including unit\n",
      "NORP            - Nationalities or religious or political groups\n",
      "ORDINAL         - \"first\", \"second\", etc.\n",
      "ORG             - Companies, agencies, institutions, etc.\n",
      "PERCENT         - Percentage, including \"%\"\n",
      "PERSON          - People, including fictional\n",
      "PRODUCT         - Objects, vehicles, foods, etc. (not services)\n",
      "QUANTITY        - Measurements, as of weight or distance\n",
      "TIME            - Times smaller than a day\n",
      "WORK_OF_ART     - Titles of books, songs, etc.\n"
     ]
    }
   ],
   "source": [
    "for label in nlp.get_pipe(\"ner\").labels:\n",
    "    print(f'{label:{15}} - {spacy.explain(label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24fcf1bc-6d63-4e5d-9997-e955657403b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant Entities\n",
    "RELEVANT_ENTITIES = {'MONEY', 'PERCENT', 'QUANTITY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91342a65-970b-4eed-a098-e57067603895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences (with context) that contain one of the relevant entities\n",
    "def extract_sent_ner(doc, relevant_entities):\n",
    "    filtered_indices = set()\n",
    "    sent_lst = list(doc.sents)\n",
    "    for i, sent in enumerate(sent_lst):\n",
    "        if any(ent.label_ in relevant_entities for ent in sent.ents):\n",
    "            filtered_indices.update(range(max(i - 1, 0),min(i + 2, len(sent_lst))))\n",
    "            \n",
    "    filtered_sentences = []\n",
    "    if filtered_indices:\n",
    "        sorted_indices = sorted(filtered_indices)\n",
    "        current_para = sent_lst[sorted_indices[0]].text\n",
    "        for i in range(1, len(sorted_indices)):\n",
    "            if sorted_indices[i] == sorted_indices[i-1] + 1:\n",
    "                current_para += ' ' + sent_lst[sorted_indices[i]].text\n",
    "            else:\n",
    "                filtered_sentences.append(current_para)\n",
    "                current_para = sent_lst[sorted_indices[i]].text\n",
    "        filtered_sentences.append(current_para)  # Append the last accumulated paragraph\n",
    "    return filtered_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6f6f4b-185a-4a04-a7f9-5ed9bd6ee511",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Helvetica, sans-serif; font-size: 16px; font-weight: bold;\">1b: Key Phrase Extraction</span>\n",
    "\n",
    "In this subsection, we categorize performance into seven distinct groups and define each group using a specific list of keywords. Additionally, we employ lemmatization techniques to identify and extract all relevant sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01061bf2-9aba-4380-afd2-079daba1c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword Lists by Category\n",
    "financial_performance_keywords = {\"revenue\", \"profit\", \"loss\", \"earnings\", \"margin\", \"expense\", \"cost\", \"dividend\", \"sales\"}\n",
    "\n",
    "market_position_keywords = {\"market\", \"share\", \"grow\", \"growth\", \"decline\", \"competitive\", \"demand\", \"supply\", \"expansion\", \"contraction\"}\n",
    "\n",
    "strategic_direction_keywords = {\"strategy\", \"acquisition\", \"merger\", \"investment\", \"divestiture\", \"innovation\", \"product\", \"launch\", \"development\"}\n",
    "\n",
    "operational_aspects_keywords = {\"production\", \"capacity\", \"inventory\", \"distribution\", \"facility\", \"outlet\", \"store\", \"operation\"}\n",
    "\n",
    "financial_indicators_keywords = {\"EBITDA\", \"cash flow\", \"capital\", \"asset\", \"liability\", \"equity\", \"return\", \"forecast\", \"guidance\"}\n",
    "\n",
    "risks_challenges_keywords = {\"risk\", \"challenge\", \"uncertain\", \"uncertainty\", \"regulation\", \"compliance\", \"legal\", \"issue\", \"problem\"}\n",
    "\n",
    "economic_factors_keywords = {\"economic\", \"recession\", \"inflation\", \"interest\", \"rate\", \"currency\", \"exchange\"}\n",
    "\n",
    "categories = {'financial_performance_keywords': financial_performance_keywords, \n",
    "                'market_position_keywords': market_position_keywords,\n",
    "                'strategic_direction_keywords': strategic_direction_keywords, \n",
    "                'operational_aspects_keywords': operational_aspects_keywords,\n",
    "                'financial_indicators_keywords': financial_indicators_keywords, \n",
    "                'risks_challenges_keywords': risks_challenges_keywords,\n",
    "                'economic_factors_keywords': economic_factors_keywords}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b97f780d-a359-4504-bdb0-49baca520a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization function\n",
    "def lemmatize_keyword(keyword):\n",
    "    doc = nlp(keyword)\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "# Use lemmatization to update lists of keywords\n",
    "for group, keywords in categories.items():\n",
    "    categories[group] = set()\n",
    "    for keyword in keywords:\n",
    "        categories[group].add(lemmatize_keyword(keyword)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c888b3bb-24e8-4478-bcac-fd68f643dca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "financial_performance_keywords :\n",
      "{'sale', 'cost', 'profit', 'dividend', 'earning', 'revenue', 'loss', 'margin', 'expense'}\n",
      "\n",
      "\n",
      "market_position_keywords :\n",
      "{'supply', 'expansion', 'growth', 'demand', 'grow', 'contraction', 'decline', 'market', 'share', 'competitive'}\n",
      "\n",
      "\n",
      "strategic_direction_keywords :\n",
      "{'investment', 'innovation', 'divestiture', 'strategy', 'merger', 'acquisition', 'product', 'launch', 'development'}\n",
      "\n",
      "\n",
      "operational_aspects_keywords :\n",
      "{'store', 'facility', 'operation', 'outlet', 'inventory', 'production', 'capacity', 'distribution'}\n",
      "\n",
      "\n",
      "financial_indicators_keywords :\n",
      "{'liability', 'ebitda', 'asset', 'return', 'cash', 'forecast', 'guidance', 'capital', 'equity'}\n",
      "\n",
      "\n",
      "risks_challenges_keywords :\n",
      "{'challenge', 'problem', 'legal', 'uncertainty', 'uncertain', 'risk', 'regulation', 'compliance', 'issue'}\n",
      "\n",
      "\n",
      "economic_factors_keywords :\n",
      "{'exchange', 'recession', 'interest', 'economic', 'rate', 'currency', 'inflation'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for group in categories:\n",
    "    print(f'{group} :')\n",
    "    print(f'{categories[group]}')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c9a19dc-ccd7-4181-bc12-b0e4b0aec197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences with context by categories using keywords\n",
    "def extract_sent_keywords(doc, keywords):\n",
    "    filtered_indices = set()\n",
    "    sent_lst = list(doc.sents)\n",
    "    for i, sent in enumerate(sent_lst):\n",
    "        if any(token.lemma_.lower() in keywords for token in sent):\n",
    "            filtered_indices.update(range(max(i - 1, 0),min(i + 2, len(sent_lst))))\n",
    "            \n",
    "    filtered_sentences = []\n",
    "    if filtered_indices:\n",
    "        sorted_indices = sorted(filtered_indices)\n",
    "        current_para = sent_lst[sorted_indices[0]].text\n",
    "        for i in range(1, len(sorted_indices)):\n",
    "            if sorted_indices[i] == sorted_indices[i-1] + 1:\n",
    "                current_para += ' ' + sent_lst[sorted_indices[i]].text\n",
    "            else:\n",
    "                filtered_sentences.append(current_para)\n",
    "                current_para = sent_lst[sorted_indices[i]].text\n",
    "        filtered_sentences.append(current_para)  # Append the last accumulated paragraph\n",
    "    return filtered_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d4b07-235b-46d1-8020-0db5b2e4cbe6",
   "metadata": {},
   "source": [
    "## Step 2: Sentiment Analysis\n",
    "\n",
    "In this section, we define functions and perform the sentiment analysis on relevant sentences and record sentiment scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474f6d4-8694-47fd-bef4-737d3aa46ac5",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Helvetica, sans-serif; font-size: 16px; font-weight: bold;\">2a: finBERT</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f846dec6-a95f-40cf-921e-3444ca679059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finbert(sentences):\n",
    "    finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "    tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "    nlp = pipeline(\"sentiment-analysis\", model=finbert, tokenizer=tokenizer)\n",
    "    scores = []\n",
    "    results = nlp(list(sentences), truncation = True, max_length = 512)\n",
    "    for i, sent in enumerate(sentences):\n",
    "        if results[i]['label'] == 'Negative':\n",
    "            results[i]['score'] *= -1\n",
    "        elif results[i]['label'] == 'Neutral':\n",
    "            results[i]['score'] = (results[i]['score'] - 0.5)*0.2       #One can also set it to be zero.\n",
    "        scores.append(results[i]['score'])\n",
    "    return sum(scores)/len(scores) if scores else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18e4f7-241a-4c2a-baea-09b3ce5e2f32",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Helvetica, sans-serif; font-size: 16px; font-weight: bold;\">2b: TextBlob</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8183a904-e55b-4472-8045-78cf72b773bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob(sentences):\n",
    "    polarity = []\n",
    "    subjectivity = []\n",
    "    for sent in sentences:\n",
    "        blob = TextBlob(sent)\n",
    "        sentiment = blob.sentiment\n",
    "        polarity.append(sentiment.polarity)\n",
    "        subjectivity.append(sentiment.subjectivity)\n",
    "    if polarity:\n",
    "        return [sum(polarity) / len(polarity), sum(subjectivity) / len(subjectivity)]\n",
    "    else:\n",
    "        return [0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562aaf1-3c32-4298-8b3b-94668dd39ffb",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Helvetica, sans-serif; font-size: 16px; font-weight: bold;\">2c: VADER</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c9b8093-5612-46f8-99ad-c1cdad3b19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader(sentences):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    scores = []\n",
    "    for sent in sentences:\n",
    "        sentiment = sia.polarity_scores(sent)\n",
    "        scores.append(sentiment['compound'])\n",
    "    return sum(scores) / len(scores) if scores else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df149e-fb90-4a38-af52-bfaeb4a25e08",
   "metadata": {},
   "source": [
    "# Step 3: Create Data Frame (Date, File Name, File Text, SentimentScores)\n",
    "\n",
    "In this section, we create a data frame and record sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f29c9ac-c612-4aa1-83b0-b84c7ed6f8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_symbols = ['VZ', 'AMZN', 'CAT', 'AAPL', 'PANW', 'PM', 'CMCSA', 'PFE', 'UBER', 'SYK', 'MMC', 'PEP',\n",
    "                  'PLD', 'GOOG', 'AMT', 'ADI', 'UPS', 'GILD', 'MS', 'WMT', 'CVX', 'TXN', 'KLAC', 'INTC',\n",
    "                  'GS', 'BLK', 'LIN', 'MA', 'MU', 'HD', 'UNP', 'AMAT', 'LLY', 'REGN', 'LMT', 'CI', 'WFC',\n",
    "                  'MRK', 'JNJ', 'QCOM', 'BAC', 'TSLA', 'CRM', 'COST', 'DHR', 'TMO', 'MSFT', 'META', 'BSX',\n",
    "                  'ELV', 'ABBV', 'MCD', 'PGR', 'NFLX', 'ACN', 'T', 'ORCL', 'IBM', 'ADP', 'AMD', 'PG', 'XOM',\n",
    "                  'LRCX', 'TJX', 'SBUX', 'PH', 'MDLZ', 'MDT', 'ABT', 'NEE', 'NOW', 'RTX', 'HON', 'BA', 'GE',\n",
    "                  'INTU', 'NVDA', 'AMGN', 'UNH', 'DIS', 'DE', 'CSCO', 'CVS', 'KO', 'AXP', 'FI', 'AVGO', 'ISRG',\n",
    "                  'ETN', 'BMY', 'NKE', 'BKNG', 'CB', 'ADBE', 'C', 'V', 'VRTX', 'COP', 'JPM']\n",
    "len(ticker_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d81623b6-1fb1-4a62-b1b8-e9500b980438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame\n",
    "# Basic information\n",
    "\n",
    "# date = []\n",
    "f_names = []\n",
    "# quarter = []\n",
    "# year = []\n",
    "# company_symbol = []\n",
    "# earning_call_text = []\n",
    "\n",
    "# Sentiment Scores\n",
    "quant_score_NER = []\n",
    "financial_performance_score = []\n",
    "market_position_score = []\n",
    "strategic_direction_score = []\n",
    "operational_aspects_score = []\n",
    "financial_indicators_score = []\n",
    "risks_challenges_score = []\n",
    "economic_factors_score = []\n",
    "\n",
    "# json loading issue\n",
    "json_prob = []\n",
    "\n",
    "# year problem issue\n",
    "year_prob = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dbe6afe1-f2d2-4f48-82cd-32233d572736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traverse files and store sentiment scores\n",
    "for ticker in ticker_symbols:\n",
    "    # Define the folder path\n",
    "    directory = 'Earnings Call Transcripts/' + ticker\n",
    "\n",
    "    # List all files in the folder\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # Loop over each file\n",
    "    for filename in files:\n",
    "        if filename == '.DS_Store':\n",
    "            continue  # Skip this file\n",
    "    \n",
    "        # Get the full path of the file\n",
    "        filepath = os.path.join(directory, filename)\n",
    "\n",
    "        # Check if the path is a regular file\n",
    "        if os.path.isfile(filepath):    \n",
    "            with open(os.path.join(directory, filename), 'r') as file:\n",
    "                try:\n",
    "                    json_file = json.load(file)\n",
    "                except:\n",
    "                    json_prob.append(filename)\n",
    "                    continue\n",
    "            try:\n",
    "                year = int(filename[-4:])\n",
    "            except:\n",
    "                year_prob.append(filename)\n",
    "                continue\n",
    "            if year < 2017:\n",
    "                continue\n",
    "            # Get Filenames, Symbol, quarter and year from filename\n",
    "            f_names.append(filename)\n",
    "            # company_symbol.append(re.search(r'([A-Z]+Q)', filename).group()[:-1])\n",
    "            # year.append(filename[-4:])\n",
    "            # quarter.append(filename[-6:-4])\n",
    "\n",
    "            # Get date\n",
    "            # d = re.search(r'(\\d{4}-\\d{2}-\\d{2}T)', json_file['data']['attributes']['publishOn']).group()[:-1]\n",
    "            # date.append(d)\n",
    "            # Get Text\n",
    "            soup = BeautifulSoup(json_file['data']['attributes']['content'], 'html.parser')\n",
    "            ect = ''\n",
    "            for p in soup.find_all('p'):\n",
    "                ect += p.text\n",
    "            # earning_call_text.append(ect)\n",
    "\n",
    "            # Get Sentiment Scores\n",
    "            doc = nlp(ect)\n",
    "            quant_score_NER.append(vader(extract_sent_ner(doc, RELEVANT_ENTITIES)))\n",
    "\n",
    "            fp = categories['financial_performance_keywords']\n",
    "            mp = categories['market_position_keywords']\n",
    "            sd = categories['strategic_direction_keywords']\n",
    "            oa = categories['operational_aspects_keywords']\n",
    "            fi = categories['financial_indicators_keywords']\n",
    "            rc = categories['risks_challenges_keywords']\n",
    "            ef = categories['economic_factors_keywords']\n",
    "\n",
    "            financial_performance_score.append(vader(extract_sent_keywords(doc, fp)))\n",
    "            market_position_score.append(vader(extract_sent_keywords(doc, mp)))\n",
    "            strategic_direction_score.append(vader(extract_sent_keywords(doc, sd)))\n",
    "            operational_aspects_score.append(vader(extract_sent_keywords(doc, oa)))\n",
    "            financial_indicators_score.append(vader(extract_sent_keywords(doc, fi)))\n",
    "            risks_challenges_score.append(vader(extract_sent_keywords(doc, rc)))\n",
    "            economic_factors_score.append(vader(extract_sent_keywords(doc, ef)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5ea4a67-f4e5-40f9-8f6c-db38895bbc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Dataframe\n",
    "data_df = pd.DataFrame({'f_names' : f_names, 'quant_score_NER' : quant_score_NER,\n",
    "                        'financial_performance_score' : financial_performance_score, \n",
    "                        'market_position_score' : market_position_score,\n",
    "                        'strategic_direction_score' : strategic_direction_score,\n",
    "                        'operational_aspects_score' : operational_aspects_score,\n",
    "                        'financial_indicators_score' : financial_indicators_score,\n",
    "                        'risks_challenges_score' : risks_challenges_score,\n",
    "                        'economic_factors_score' : economic_factors_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "754a507f-21ad-4860-b65d-d1e97d6db0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_names</th>\n",
       "      <th>quant_score_NER</th>\n",
       "      <th>financial_performance_score</th>\n",
       "      <th>market_position_score</th>\n",
       "      <th>strategic_direction_score</th>\n",
       "      <th>operational_aspects_score</th>\n",
       "      <th>financial_indicators_score</th>\n",
       "      <th>risks_challenges_score</th>\n",
       "      <th>economic_factors_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VZQ42023</td>\n",
       "      <td>0.641895</td>\n",
       "      <td>0.799723</td>\n",
       "      <td>0.773718</td>\n",
       "      <td>0.684652</td>\n",
       "      <td>0.668230</td>\n",
       "      <td>0.610928</td>\n",
       "      <td>0.533500</td>\n",
       "      <td>0.630167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VZQ42022</td>\n",
       "      <td>0.500700</td>\n",
       "      <td>0.656455</td>\n",
       "      <td>0.695640</td>\n",
       "      <td>0.702053</td>\n",
       "      <td>0.595356</td>\n",
       "      <td>0.775747</td>\n",
       "      <td>0.500325</td>\n",
       "      <td>0.601088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VZQ12022</td>\n",
       "      <td>0.710535</td>\n",
       "      <td>0.645537</td>\n",
       "      <td>0.797707</td>\n",
       "      <td>0.717752</td>\n",
       "      <td>0.508138</td>\n",
       "      <td>0.654721</td>\n",
       "      <td>0.212983</td>\n",
       "      <td>0.682775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VZQ22023</td>\n",
       "      <td>0.663882</td>\n",
       "      <td>0.661021</td>\n",
       "      <td>0.726271</td>\n",
       "      <td>0.646467</td>\n",
       "      <td>0.725710</td>\n",
       "      <td>0.734340</td>\n",
       "      <td>0.289257</td>\n",
       "      <td>0.644245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VZQ32023</td>\n",
       "      <td>0.610950</td>\n",
       "      <td>0.677594</td>\n",
       "      <td>0.711575</td>\n",
       "      <td>0.699431</td>\n",
       "      <td>0.588673</td>\n",
       "      <td>0.799629</td>\n",
       "      <td>0.424017</td>\n",
       "      <td>0.605820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>JPMQ42021</td>\n",
       "      <td>0.602292</td>\n",
       "      <td>0.527262</td>\n",
       "      <td>0.642297</td>\n",
       "      <td>0.633158</td>\n",
       "      <td>0.453682</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.016520</td>\n",
       "      <td>0.511783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>JPMQ42019</td>\n",
       "      <td>0.521281</td>\n",
       "      <td>0.661630</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.639760</td>\n",
       "      <td>0.599325</td>\n",
       "      <td>0.649774</td>\n",
       "      <td>0.570791</td>\n",
       "      <td>0.609950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>JPMQ42017</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>0.676751</td>\n",
       "      <td>0.713940</td>\n",
       "      <td>0.656974</td>\n",
       "      <td>0.367900</td>\n",
       "      <td>0.558776</td>\n",
       "      <td>0.669686</td>\n",
       "      <td>0.669714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>JPMQ42018</td>\n",
       "      <td>0.526721</td>\n",
       "      <td>0.515767</td>\n",
       "      <td>0.640264</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.630465</td>\n",
       "      <td>0.248315</td>\n",
       "      <td>0.500603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>JPMQ42020</td>\n",
       "      <td>0.470500</td>\n",
       "      <td>0.633368</td>\n",
       "      <td>0.571784</td>\n",
       "      <td>0.687410</td>\n",
       "      <td>0.626964</td>\n",
       "      <td>0.628916</td>\n",
       "      <td>0.288547</td>\n",
       "      <td>0.660378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2705 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_names  quant_score_NER  financial_performance_score  \\\n",
       "0      VZQ42023         0.641895                     0.799723   \n",
       "1      VZQ42022         0.500700                     0.656455   \n",
       "2      VZQ12022         0.710535                     0.645537   \n",
       "3      VZQ22023         0.663882                     0.661021   \n",
       "4      VZQ32023         0.610950                     0.677594   \n",
       "...         ...              ...                          ...   \n",
       "2700  JPMQ42021         0.602292                     0.527262   \n",
       "2701  JPMQ42019         0.521281                     0.661630   \n",
       "2702  JPMQ42017         0.711100                     0.676751   \n",
       "2703  JPMQ42018         0.526721                     0.515767   \n",
       "2704  JPMQ42020         0.470500                     0.633368   \n",
       "\n",
       "      market_position_score  strategic_direction_score  \\\n",
       "0                  0.773718                   0.684652   \n",
       "1                  0.695640                   0.702053   \n",
       "2                  0.797707                   0.717752   \n",
       "3                  0.726271                   0.646467   \n",
       "4                  0.711575                   0.699431   \n",
       "...                     ...                        ...   \n",
       "2700               0.642297                   0.633158   \n",
       "2701               0.783019                   0.639760   \n",
       "2702               0.713940                   0.656974   \n",
       "2703               0.640264                   0.508442   \n",
       "2704               0.571784                   0.687410   \n",
       "\n",
       "      operational_aspects_score  financial_indicators_score  \\\n",
       "0                      0.668230                    0.610928   \n",
       "1                      0.595356                    0.775747   \n",
       "2                      0.508138                    0.654721   \n",
       "3                      0.725710                    0.734340   \n",
       "4                      0.588673                    0.799629   \n",
       "...                         ...                         ...   \n",
       "2700                   0.453682                    0.589147   \n",
       "2701                   0.599325                    0.649774   \n",
       "2702                   0.367900                    0.558776   \n",
       "2703                   0.024400                    0.630465   \n",
       "2704                   0.626964                    0.628916   \n",
       "\n",
       "      risks_challenges_score  economic_factors_score  \n",
       "0                   0.533500                0.630167  \n",
       "1                   0.500325                0.601088  \n",
       "2                   0.212983                0.682775  \n",
       "3                   0.289257                0.644245  \n",
       "4                   0.424017                0.605820  \n",
       "...                      ...                     ...  \n",
       "2700                0.016520                0.511783  \n",
       "2701                0.570791                0.609950  \n",
       "2702                0.669686                0.669714  \n",
       "2703                0.248315                0.500603  \n",
       "2704                0.288547                0.660378  \n",
       "\n",
       "[2705 rows x 9 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9948f225-e515-47eb-9f1c-5c9e7e4e7071",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('sentiment_scores.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
